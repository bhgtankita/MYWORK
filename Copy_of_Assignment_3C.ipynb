{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_Assignment_3C.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhgtankita/MYWORK/blob/master/Copy_of_Assignment_3C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrZE4ST1ymTq",
        "colab_type": "code",
        "outputId": "55d7282c-13c0-4846-aadd-9412dabe2c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbqCPqpSzNth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls 'gdrive/My Drive/Weights'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8edSiHPi2N5l",
        "colab_type": "code",
        "outputId": "b624c4f8-4794-462c-a35e-73f145ab50da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras\n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint,CSVLogger\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 10\n",
        "num_filter = 20"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hkvQwOH2cCO",
        "colab_type": "code",
        "outputId": "f79b43f7-2329-4875-d06a-e79536ee2b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 21s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztoDypc63gEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def space_to_depth_x2(x):\n",
        "    return tf.space_to_depth(x, block_size=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGq0ES2bpKWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compression = 2\n",
        "num_filter = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Soq9kk_RlekX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_conv_block(input, num_filter = 16):\n",
        "  global compression\n",
        "  temp = input\n",
        "  compression = 2\n",
        "  \n",
        "  for i in range(5):\n",
        "    BatchNorm = BatchNormalization()(temp)\n",
        "    Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(BatchNorm)\n",
        "    lrelu = LeakyReLU(alpha=0.1)(Conv2D_3_3)\n",
        "    compression *= 2\n",
        "    temp = lrelu\n",
        "  \n",
        "  temp = MaxPooling2D(pool_size=(2, 2))(temp)\n",
        "\n",
        "  return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPmD22jAnPG0",
        "colab_type": "code",
        "outputId": "934bab0e-5cca-488a-9f1c-ae2ed093d54b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "\n",
        "First_Block = add_conv_block(input, num_filter)\n",
        "Second_Block = add_conv_block(First_Block, num_filter)\n",
        "Third_Block = add_conv_block(Second_Block, num_filter)\n",
        "Fourth_Block = add_conv_block(Third_Block, num_filter)\n",
        "\n",
        "#First_Block_Reduce = space_to_depth_x2(First_Block)\n",
        "\n",
        "First_Block_Reduce = MaxPooling2D(pool_size=(2, 2))(First_Block)\n",
        "First_Block_Reduce = MaxPooling2D(pool_size=(2, 2))(First_Block_Reduce)\n",
        "First_Block_Reduce = MaxPooling2D(pool_size=(2, 2))(First_Block_Reduce)\n",
        "\n",
        "concat = Concatenate(axis=-1)([First_Block_Reduce,Fourth_Block])\n",
        "\n",
        "#lastlayer = Flatten()(concat)\n",
        "#output = Dense(num_classes, activation='softmax')(lastlayer)\n",
        "\n",
        "layer1 = BatchNormalization(name='norm_1')(concat)\n",
        "layer1 = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_1', use_bias=False)(layer1)\n",
        "layer1 = LeakyReLU(alpha=0.1)(layer1)\n",
        "\n",
        "layer2 = BatchNormalization(name='norm_2')(layer1)\n",
        "layer2 = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_2', use_bias=False)(layer2)\n",
        "layer2 = LeakyReLU(alpha=0.1)(layer2)\n",
        "\n",
        "layer3 = BatchNormalization(name='norm_3')(layer2)\n",
        "layer3 = Conv2D(32, (1,1), strides=(1,1), padding='same', name='conv_3', use_bias=False)(layer3)\n",
        "layer3 = LeakyReLU(alpha=0.1)(layer3)\n",
        "\n",
        "layer4 = BatchNormalization(name='norm_4')(layer3)\n",
        "layer4 = Conv2D(10, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(layer4)\n",
        "layer4 = LeakyReLU(alpha=0.1)(layer4)\n",
        "\n",
        "output = AveragePooling2D(pool_size=(2,2))(layer4)\n",
        "output = Activation('softmax')(output)\n",
        "output = Flatten()(output)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8thgH_8qCS4",
        "colab_type": "code",
        "outputId": "eb968fe1-53a8-4f0d-a0ae-81392f2edd12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3068
        }
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 3)    12          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 32)   864         batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 32)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 64)   18432       batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 128)  73728       batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 32, 32, 128)  0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 128)  512         leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 256)  294912      batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 32, 32, 256)  0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 256)  1024        leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 512)  1179648     batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 32, 32, 512)  0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 512)  0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 512)  2048        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 32)   147456      batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 16, 16, 32)   0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 32)   128         leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   18432       batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 16, 16, 64)   0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   256         leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 128)  73728       batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 16, 16, 128)  0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 128)  512         leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 256)  294912      batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 16, 16, 256)  0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 256)  1024        leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 512)  1179648     batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 16, 16, 512)  0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 512)    0           leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 8, 8, 512)    2048        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 8, 8, 32)     147456      batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 8, 8, 32)     0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 8, 8, 32)     128         leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 8, 8, 64)     18432       batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, 8, 8, 64)     0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 8, 8, 64)     256         leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 8, 8, 128)    73728       batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, 8, 8, 128)    0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 128)    512         leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 256)    294912      batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, 8, 8, 256)    0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 256)    1024        leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 512)    1179648     batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, 8, 8, 512)    0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 512)    0           leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 4, 4, 512)    2048        max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 4, 4, 32)     147456      batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, 4, 4, 32)     0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 4, 4, 32)     128         leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 4, 4, 64)     18432       batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, 4, 4, 64)     0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 4, 4, 64)     256         leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 4, 4, 128)    73728       batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, 4, 4, 128)    0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 4, 4, 128)    512         leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 4, 4, 256)    294912      batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, 4, 4, 256)    0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 4, 4, 256)    1024        leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 512)    0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 4, 4, 512)    1179648     batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 4, 4, 512)    0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, 4, 4, 512)    0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 2, 2, 512)    0           max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 2, 2, 512)    0           leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 2, 2, 1024)   0           max_pooling2d_7[0][0]            \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_1 (BatchNormalization)     (None, 2, 2, 1024)   4096        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_1 (Conv2D)                 (None, 2, 2, 512)    524288      norm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, 2, 2, 512)    0           conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "norm_2 (BatchNormalization)     (None, 2, 2, 512)    2048        leaky_re_lu_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_2 (Conv2D)                 (None, 2, 2, 64)     32768       norm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)      (None, 2, 2, 64)     0           conv_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "norm_3 (BatchNormalization)     (None, 2, 2, 64)     256         leaky_re_lu_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_3 (Conv2D)                 (None, 2, 2, 32)     2048        norm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)      (None, 2, 2, 32)     0           conv_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "norm_4 (BatchNormalization)     (None, 2, 2, 32)     128         leaky_re_lu_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_4 (Conv2D)                 (None, 2, 2, 10)     320         norm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)      (None, 2, 2, 10)     0           conv_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 10)     0           leaky_re_lu_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 1, 1, 10)     0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 10)           0           activation_1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 7,289,900\n",
            "Trainable params: 7,279,718\n",
            "Non-trainable params: 10,182\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apCwOjvZ4Kts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgJzI_BgY1MH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen = ImageDataGenerator( #featurewise_center=True,\n",
        "                          #featurewise_std_normalization=True,\n",
        "                          rotation_range=20, \n",
        "                          width_shift_range=0.2, \n",
        "                          #shear_range=0.2,\n",
        "                          height_shift_range=0.2, \n",
        "                          zoom_range=0.15,\n",
        "                          horizontal_flip=True)\n",
        "\n",
        "valid_gen = ImageDataGenerator()\n",
        "train_generator = gen.flow(x_train, y_train, batch_size=batch_size)\n",
        "validation_generator = valid_gen.flow(x_test, y_test, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMxYERCWY7-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
        "                              factor=0.1, \n",
        "                              patience=3, \n",
        "                              mode='auto', \n",
        "                              min_delta=0.0001, \n",
        "                              cooldown=0, \n",
        "                              min_lr=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvj5NCM7j8LM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checkpoint = GoogleDriveCheckpoint('Ass3C_weights.h5', drive, save_best_only=True, save_weights_only=True, monitor='val_loss',\n",
        "#                                       verbose=1)\n",
        "\n",
        "#logger = CSVLogger(os.path.join(\"./training\", \"training_24x24.log\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUwwz-jdUaC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint('gdrive/My Drive/Weights/weights_ASS3C.{epoch:04d}-{val_loss:.2f}.hdf5',\n",
        "                             monitor='val_loss', \n",
        "                             save_best_only=True )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqsb7zVR48Or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "logger = CSVLogger(os.path.join(\"gdrive/My Drive/Weights/\", \"training_24x24.log\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VavtPBIFZSXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks_list = [reduce_lr,checkpoint,logger]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLaFy2AO4TLl",
        "colab_type": "code",
        "outputId": "d5105d3d-bf9b-4bc0-d8ae-feb2f7423e8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1909
        }
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 239s 5ms/step - loss: 1.2717 - acc: 0.5546 - val_loss: 2.0683 - val_acc: 0.4780\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 223s 4ms/step - loss: 0.7950 - acc: 0.7266 - val_loss: 1.4176 - val_acc: 0.6207\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 222s 4ms/step - loss: 0.6196 - acc: 0.7898 - val_loss: 0.9194 - val_acc: 0.7231\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.5012 - acc: 0.8293 - val_loss: 0.7888 - val_acc: 0.7517\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.4168 - acc: 0.8576 - val_loss: 0.7281 - val_acc: 0.7769\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 220s 4ms/step - loss: 0.3492 - acc: 0.8810 - val_loss: 0.5909 - val_acc: 0.8181\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 220s 4ms/step - loss: 0.2941 - acc: 0.8989 - val_loss: 0.6338 - val_acc: 0.8113\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 220s 4ms/step - loss: 0.2350 - acc: 0.9197 - val_loss: 0.6276 - val_acc: 0.8091\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.1986 - acc: 0.9329 - val_loss: 0.6748 - val_acc: 0.8077\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0876 - acc: 0.9747 - val_loss: 0.4205 - val_acc: 0.8690\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 220s 4ms/step - loss: 0.0460 - acc: 0.9902 - val_loss: 0.4194 - val_acc: 0.8694\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 220s 4ms/step - loss: 0.0312 - acc: 0.9954 - val_loss: 0.4211 - val_acc: 0.8710\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 220s 4ms/step - loss: 0.0225 - acc: 0.9978 - val_loss: 0.4268 - val_acc: 0.8721\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 220s 4ms/step - loss: 0.0168 - acc: 0.9987 - val_loss: 0.4331 - val_acc: 0.8717\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0121 - acc: 0.9994 - val_loss: 0.4332 - val_acc: 0.8722\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0120 - acc: 0.9996 - val_loss: 0.4335 - val_acc: 0.8731\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0112 - acc: 0.9997 - val_loss: 0.4344 - val_acc: 0.8729\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0105 - acc: 0.9997 - val_loss: 0.4339 - val_acc: 0.8728\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0108 - acc: 0.9996 - val_loss: 0.4339 - val_acc: 0.8732\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0107 - acc: 0.9996 - val_loss: 0.4345 - val_acc: 0.8723\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0103 - acc: 0.9997 - val_loss: 0.4344 - val_acc: 0.8733\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0104 - acc: 0.9997 - val_loss: 0.4349 - val_acc: 0.8724\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 220s 4ms/step - loss: 0.0106 - acc: 0.9996 - val_loss: 0.4347 - val_acc: 0.8726\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 220s 4ms/step - loss: 0.0104 - acc: 0.9997 - val_loss: 0.4342 - val_acc: 0.8731\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0105 - acc: 0.9996 - val_loss: 0.4341 - val_acc: 0.8728\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0103 - acc: 0.9996 - val_loss: 0.4347 - val_acc: 0.8735\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0106 - acc: 0.9996 - val_loss: 0.4346 - val_acc: 0.8731\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0105 - acc: 0.9997 - val_loss: 0.4348 - val_acc: 0.8730\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0106 - acc: 0.9997 - val_loss: 0.4341 - val_acc: 0.8727\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0102 - acc: 0.9997 - val_loss: 0.4343 - val_acc: 0.8735\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0107 - acc: 0.9997 - val_loss: 0.4345 - val_acc: 0.8724\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0105 - acc: 0.9997 - val_loss: 0.4345 - val_acc: 0.8730\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0108 - acc: 0.9998 - val_loss: 0.4346 - val_acc: 0.8725\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0104 - acc: 0.9996 - val_loss: 0.4344 - val_acc: 0.8727\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0106 - acc: 0.9998 - val_loss: 0.4344 - val_acc: 0.8736\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0107 - acc: 0.9997 - val_loss: 0.4344 - val_acc: 0.8729\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0106 - acc: 0.9996 - val_loss: 0.4344 - val_acc: 0.8728\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0104 - acc: 0.9997 - val_loss: 0.4340 - val_acc: 0.8730\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0103 - acc: 0.9998 - val_loss: 0.4345 - val_acc: 0.8725\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0108 - acc: 0.9996 - val_loss: 0.4348 - val_acc: 0.8721\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0107 - acc: 0.9997 - val_loss: 0.4341 - val_acc: 0.8726\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0103 - acc: 0.9997 - val_loss: 0.4346 - val_acc: 0.8727\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0104 - acc: 0.9995 - val_loss: 0.4345 - val_acc: 0.8729\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0106 - acc: 0.9997 - val_loss: 0.4343 - val_acc: 0.8728\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0101 - acc: 0.9998 - val_loss: 0.4347 - val_acc: 0.8725\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0105 - acc: 0.9997 - val_loss: 0.4338 - val_acc: 0.8729\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 220s 4ms/step - loss: 0.0104 - acc: 0.9997 - val_loss: 0.4344 - val_acc: 0.8727\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0108 - acc: 0.9996 - val_loss: 0.4344 - val_acc: 0.8730\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 220s 4ms/step - loss: 0.0108 - acc: 0.9996 - val_loss: 0.4340 - val_acc: 0.8725\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 220s 4ms/step - loss: 0.0104 - acc: 0.9997 - val_loss: 0.4339 - val_acc: 0.8728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f03816f5b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTfZIGrf4Uyd",
        "colab_type": "code",
        "outputId": "def3dcd1-5541-454c-c68b-9176d9ec73ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 17s 2ms/step\n",
            "Test loss: 0.4339426311135292\n",
            "Test accuracy: 0.8728\n",
            "Saved the model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jiyb9TlVGsZs",
        "colab_type": "code",
        "outputId": "fc3029cf-8b71-42f1-c7b6-9a990f7eacc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.save_weights(\"Yolo_Basic_model2.h5\")\n",
        "print(\"Saved the model to disk\")\n",
        "from google.colab import files\n",
        "\n",
        "files.download('Yolo_Basic_model2.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved the model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9A3pesKbUJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}