{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolo_Basic.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhgtankita/MYWORK/blob/master/Yolo_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiRcBbdjfN4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsnLL1nEju2t",
        "colab_type": "code",
        "outputId": "80cf3896-d74e-4077-9bba-816d46d68749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!curl https://raw.githubusercontent.com/dexterfichuk/GoogleDriveCheckpoint/master/google_drive_checkpoint.py -O"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  4522  100  4522    0     0  37065      0 --:--:-- --:--:-- --:--:-- 37065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tViACaQDj0qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google_drive_checkpoint import GoogleDriveCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8edSiHPi2N5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras\n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint,CSVLogger\n",
        "\n",
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 10\n",
        "num_filter = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hkvQwOH2cCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztoDypc63gEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def space_to_depth_x2(x):\n",
        "    return tf.space_to_depth(x, block_size=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNnGm8Tv2fR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "\n",
        "# Layer 1\n",
        "layer1 = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input)\n",
        "layer1 = BatchNormalization(name='norm_1')(layer1)\n",
        "layer1 = LeakyReLU(alpha=0.1)(layer1)\n",
        "layer1 = MaxPooling2D(pool_size=(2, 2))(layer1)\n",
        "\n",
        "# Layer 2\n",
        "layer2 = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(layer1)\n",
        "layer2 = BatchNormalization(name='norm_2')(layer2)\n",
        "layer2 = LeakyReLU(alpha=0.1)(layer2)\n",
        "layer2 = MaxPooling2D(pool_size=(2, 2))(layer2)\n",
        "\n",
        "# Layer 3\n",
        "layer3 = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(layer2)\n",
        "layer3 = BatchNormalization(name='norm_3')(layer3)\n",
        "layer3 = LeakyReLU(alpha=0.1)(layer3)\n",
        "\n",
        "# Layer 4\n",
        "layer4 = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(layer3)\n",
        "layer4 = BatchNormalization(name='norm_4')(layer4)\n",
        "layer4 = LeakyReLU(alpha=0.1)(layer4)\n",
        "\n",
        "# Layer 5\n",
        "layer5 = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(layer4)\n",
        "layer5 = BatchNormalization(name='norm_5')(layer5)\n",
        "layer5 = LeakyReLU(alpha=0.1)(layer5)\n",
        "layer5 = MaxPooling2D(pool_size=(2, 2))(layer5)\n",
        "\n",
        "# Layer 6\n",
        "layer6 = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(layer5)\n",
        "layer6 = BatchNormalization(name='norm_6')(layer6)\n",
        "layer6 = LeakyReLU(alpha=0.1)(layer6)\n",
        "\n",
        "# Layer 7\n",
        "layer7 = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(layer6)\n",
        "layer7 = BatchNormalization(name='norm_7')(layer7)\n",
        "layer7 = LeakyReLU(alpha=0.1)(layer7)\n",
        "\n",
        "# Layer 8\n",
        "layer8 = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(layer7)\n",
        "layer8 = BatchNormalization(name='norm_8')(layer8)\n",
        "layer8 = LeakyReLU(alpha=0.1)(layer8)\n",
        "layer8 = MaxPooling2D(pool_size=(2, 2))(layer8)\n",
        "\n",
        "# Layer 9\n",
        "layer9 = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(layer8)\n",
        "layer9 = BatchNormalization(name='norm_9')(layer9)\n",
        "layer9 = LeakyReLU(alpha=0.1)(layer9)\n",
        "\n",
        "# Layer 10\n",
        "layer10 = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(layer9)\n",
        "layer10 = BatchNormalization(name='norm_10')(layer10)\n",
        "layer10 = LeakyReLU(alpha=0.1)(layer10)\n",
        "\n",
        "# Layer 11\n",
        "layer11 = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(layer10)\n",
        "layer11 = BatchNormalization(name='norm_11')(layer11)\n",
        "layer11 = LeakyReLU(alpha=0.1)(layer11)\n",
        "\n",
        "# Layer 12\n",
        "layer12 = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(layer11)\n",
        "layer12 = BatchNormalization(name='norm_12')(layer12)\n",
        "layer12 = LeakyReLU(alpha=0.1)(layer12)\n",
        "\n",
        "skip_connection = layer12\n",
        "\n",
        "# Layer 13\n",
        "layer13 = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(layer12)\n",
        "layer13 = BatchNormalization(name='norm_13')(layer13)\n",
        "layer13 = LeakyReLU(alpha=0.1)(layer13)\n",
        "layer13 = MaxPooling2D(pool_size=(2, 2))(layer13)\n",
        "\n",
        "# Layer 14\n",
        "layer14 = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(layer13)\n",
        "layer14 = BatchNormalization(name='norm_14')(layer14)\n",
        "layer14 = LeakyReLU(alpha=0.1)(layer14)\n",
        "\n",
        "# Layer 15\n",
        "layer15 = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(layer14)\n",
        "layer15 = BatchNormalization(name='norm_15')(layer15)\n",
        "layer15 = LeakyReLU(alpha=0.1)(layer15)\n",
        "\n",
        "# Layer 16\n",
        "layer16 = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(layer15)\n",
        "layer16 = BatchNormalization(name='norm_16')(layer16)\n",
        "layer16 = LeakyReLU(alpha=0.1)(layer16)\n",
        "\n",
        "# Layer 17\n",
        "layer17 = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(layer16)\n",
        "layer17 = BatchNormalization(name='norm_17')(layer17)\n",
        "layer17 = LeakyReLU(alpha=0.1)(layer17)\n",
        "\n",
        "# Layer 18\n",
        "layer18 = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(layer17)\n",
        "layer18 = BatchNormalization(name='norm_18')(layer18)\n",
        "layer18 = LeakyReLU(alpha=0.1)(layer18)\n",
        "\n",
        "# Layer 19\n",
        "layer19 = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(layer18)\n",
        "layer19 = BatchNormalization(name='norm_19')(layer19)\n",
        "layer19 = LeakyReLU(alpha=0.1)(layer19)\n",
        "\n",
        "# Layer 20\n",
        "layer20 = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(layer19)\n",
        "layer20 = BatchNormalization(name='norm_20')(layer20)\n",
        "layer20 = LeakyReLU(alpha=0.1)(layer20)\n",
        "\n",
        "# Layer 21\n",
        "skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
        "skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
        "skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
        "skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
        "\n",
        "layer21 = concatenate([skip_connection, layer20])\n",
        "\n",
        "# Layer 22\n",
        "layer22 = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(layer21)\n",
        "layer22 = BatchNormalization(name='norm_22')(layer22)\n",
        "layer22 = LeakyReLU(alpha=0.1)(layer22)\n",
        "\n",
        "# Layer 23\n",
        "layer23 = Flatten()(layer22)\n",
        "\n",
        "output = Dense(num_classes, activation='softmax')(layer23)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jeh0VAxy26NV",
        "colab_type": "code",
        "outputId": "126ee117-c391-4b70-92c0-6a07ec50e985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2705
        }
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_1 (Conv2D)                 (None, 32, 32, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "norm_1 (BatchNormalization)     (None, 32, 32, 32)   128         conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)      (None, 32, 32, 32)   0           norm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 32)   0           leaky_re_lu_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_2 (Conv2D)                 (None, 16, 16, 64)   18432       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_2 (BatchNormalization)     (None, 16, 16, 64)   256         conv_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)      (None, 16, 16, 64)   0           norm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 64)     0           leaky_re_lu_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_3 (Conv2D)                 (None, 8, 8, 128)    73728       max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_3 (BatchNormalization)     (None, 8, 8, 128)    512         conv_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)      (None, 8, 8, 128)    0           norm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_4 (Conv2D)                 (None, 8, 8, 64)     8192        leaky_re_lu_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_4 (BatchNormalization)     (None, 8, 8, 64)     256         conv_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)      (None, 8, 8, 64)     0           norm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_5 (Conv2D)                 (None, 8, 8, 128)    73728       leaky_re_lu_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_5 (BatchNormalization)     (None, 8, 8, 128)    512         conv_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)      (None, 8, 8, 128)    0           norm_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 4, 4, 128)    0           leaky_re_lu_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_6 (Conv2D)                 (None, 4, 4, 256)    294912      max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_6 (BatchNormalization)     (None, 4, 4, 256)    1024        conv_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)      (None, 4, 4, 256)    0           norm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_7 (Conv2D)                 (None, 4, 4, 128)    32768       leaky_re_lu_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_7 (BatchNormalization)     (None, 4, 4, 128)    512         conv_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)      (None, 4, 4, 128)    0           norm_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_8 (Conv2D)                 (None, 4, 4, 256)    294912      leaky_re_lu_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_8 (BatchNormalization)     (None, 4, 4, 256)    1024        conv_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)      (None, 4, 4, 256)    0           norm_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 2, 2, 256)    0           leaky_re_lu_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_9 (Conv2D)                 (None, 2, 2, 512)    1179648     max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_9 (BatchNormalization)     (None, 2, 2, 512)    2048        conv_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)      (None, 2, 2, 512)    0           norm_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_10 (Conv2D)                (None, 2, 2, 256)    131072      leaky_re_lu_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_10 (BatchNormalization)    (None, 2, 2, 256)    1024        conv_10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)      (None, 2, 2, 256)    0           norm_10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_11 (Conv2D)                (None, 2, 2, 512)    1179648     leaky_re_lu_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_11 (BatchNormalization)    (None, 2, 2, 512)    2048        conv_11[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)      (None, 2, 2, 512)    0           norm_11[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_12 (Conv2D)                (None, 2, 2, 256)    131072      leaky_re_lu_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_12 (BatchNormalization)    (None, 2, 2, 256)    1024        conv_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_34 (LeakyReLU)      (None, 2, 2, 256)    0           norm_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_13 (Conv2D)                (None, 2, 2, 512)    1179648     leaky_re_lu_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_13 (BatchNormalization)    (None, 2, 2, 512)    2048        conv_13[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_35 (LeakyReLU)      (None, 2, 2, 512)    0           norm_13[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 1, 1, 512)    0           leaky_re_lu_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_14 (Conv2D)                (None, 1, 1, 1024)   4718592     max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "norm_14 (BatchNormalization)    (None, 1, 1, 1024)   4096        conv_14[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_36 (LeakyReLU)      (None, 1, 1, 1024)   0           norm_14[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_15 (Conv2D)                (None, 1, 1, 512)    524288      leaky_re_lu_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_15 (BatchNormalization)    (None, 1, 1, 512)    2048        conv_15[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_37 (LeakyReLU)      (None, 1, 1, 512)    0           norm_15[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_16 (Conv2D)                (None, 1, 1, 1024)   4718592     leaky_re_lu_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_16 (BatchNormalization)    (None, 1, 1, 1024)   4096        conv_16[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_38 (LeakyReLU)      (None, 1, 1, 1024)   0           norm_16[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_17 (Conv2D)                (None, 1, 1, 512)    524288      leaky_re_lu_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_17 (BatchNormalization)    (None, 1, 1, 512)    2048        conv_17[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_39 (LeakyReLU)      (None, 1, 1, 512)    0           norm_17[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_18 (Conv2D)                (None, 1, 1, 1024)   4718592     leaky_re_lu_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_18 (BatchNormalization)    (None, 1, 1, 1024)   4096        conv_18[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_40 (LeakyReLU)      (None, 1, 1, 1024)   0           norm_18[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_19 (Conv2D)                (None, 1, 1, 1024)   9437184     leaky_re_lu_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_19 (BatchNormalization)    (None, 1, 1, 1024)   4096        conv_19[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_21 (Conv2D)                (None, 2, 2, 64)     16384       leaky_re_lu_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_41 (LeakyReLU)      (None, 1, 1, 1024)   0           norm_19[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "norm_21 (BatchNormalization)    (None, 2, 2, 64)     256         conv_21[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_20 (Conv2D)                (None, 1, 1, 1024)   9437184     leaky_re_lu_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_43 (LeakyReLU)      (None, 2, 2, 64)     0           norm_21[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "norm_20 (BatchNormalization)    (None, 1, 1, 1024)   4096        conv_20[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 1, 1, 256)    0           leaky_re_lu_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_42 (LeakyReLU)      (None, 1, 1, 1024)   0           norm_20[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 1, 1, 1280)   0           lambda_2[0][0]                   \n",
            "                                                                 leaky_re_lu_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_22 (Conv2D)                (None, 1, 1, 1024)   11796480    concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "norm_22 (BatchNormalization)    (None, 1, 1, 1024)   4096        conv_22[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_44 (LeakyReLU)      (None, 1, 1, 1024)   0           norm_22[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 1024)         0           leaky_re_lu_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           10250       flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 50,541,802\n",
            "Trainable params: 50,521,130\n",
            "Non-trainable params: 20,672\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apCwOjvZ4Kts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvj5NCM7j8LM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = GoogleDriveCheckpoint('yolo_weights.h5', drive, save_best_only=True, save_weights_only=True, monitor='val_loss',\n",
        "                                       verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUwwz-jdUaC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checkpoint = ModelCheckpoint('./drive/weights_YOLO.{epoch:04d}-{val_loss:.2f}.hdf5',\n",
        "#                             monitor='val_loss', \n",
        "#                             save_best_only=True )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLaFy2AO4TLl",
        "colab_type": "code",
        "outputId": "dcccdafa-de03-4b53-8e63-82110ccf9afe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4314
        }
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/300\n",
            "50000/50000 [==============================] - 97s 2ms/step - loss: 1.4371 - acc: 0.4808 - val_loss: 1.7500 - val_acc: 0.4230\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.75002, saving model to yolo_weights.h5\n",
            "Uploaded file yolo_weights-1.7500247024536133.h5 to drive with ID 1eTd2Pfe3m5M_9Rn3QvaEXPG_1Ns2qzCY\n",
            "Epoch 2/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 1.0017 - acc: 0.6465 - val_loss: 1.4611 - val_acc: 0.5297\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.75002 to 1.46110, saving model to yolo_weights.h5\n",
            "Uploaded file yolo_weights-1.461104449081421.h5 to drive with ID 1Q0gV7s_OPOmCaZDZna4lSjpGXOhEF4W2\n",
            "Epoch 3/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.7985 - acc: 0.7195 - val_loss: 0.9536 - val_acc: 0.6779\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.46110 to 0.95360, saving model to yolo_weights.h5\n",
            "Uploaded file yolo_weights-0.9536020474433899.h5 to drive with ID 1-eET7T_hx0vO4LbTHdJx9or7fAPCZ4S7\n",
            "Epoch 4/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.6638 - acc: 0.7688 - val_loss: 1.0057 - val_acc: 0.6677\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.95360\n",
            "Epoch 5/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.5743 - acc: 0.7999 - val_loss: 0.8901 - val_acc: 0.7096\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.95360 to 0.89005, saving model to yolo_weights.h5\n",
            "Uploaded file yolo_weights-0.8900539884567261.h5 to drive with ID 1xcWcC6GRW29MF8PK0bNLqQnPXEopiKha\n",
            "Epoch 6/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.4941 - acc: 0.8295 - val_loss: 0.8834 - val_acc: 0.7237\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.89005 to 0.88344, saving model to yolo_weights.h5\n",
            "Uploaded file yolo_weights-0.8834430488586426.h5 to drive with ID 1aFrhXxBmgBKeiV4ek20mWyOzBCUNivmq\n",
            "Epoch 7/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.4250 - acc: 0.8532 - val_loss: 1.2225 - val_acc: 0.6495\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.88344\n",
            "Epoch 8/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.3923 - acc: 0.8649 - val_loss: 0.9037 - val_acc: 0.7209\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.88344\n",
            "Epoch 9/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.3182 - acc: 0.8882 - val_loss: 0.8823 - val_acc: 0.7305\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.88344 to 0.88232, saving model to yolo_weights.h5\n",
            "Uploaded file yolo_weights-0.8823205682754517.h5 to drive with ID 1F8vENCC9Al11S2OQlr0KN4yuGZSgK6nF\n",
            "Epoch 10/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.2667 - acc: 0.9082 - val_loss: 0.9158 - val_acc: 0.7442\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.88232\n",
            "Epoch 11/300\n",
            "50000/50000 [==============================] - 91s 2ms/step - loss: 0.2303 - acc: 0.9204 - val_loss: 0.9411 - val_acc: 0.7441\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.88232\n",
            "Epoch 12/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.2044 - acc: 0.9289 - val_loss: 1.0045 - val_acc: 0.7379\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.88232\n",
            "Epoch 13/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.1739 - acc: 0.9390 - val_loss: 0.9321 - val_acc: 0.7551\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.88232\n",
            "Epoch 14/300\n",
            "50000/50000 [==============================] - 91s 2ms/step - loss: 0.1496 - acc: 0.9471 - val_loss: 1.1565 - val_acc: 0.7307\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.88232\n",
            "Epoch 15/300\n",
            "50000/50000 [==============================] - 91s 2ms/step - loss: 0.1365 - acc: 0.9525 - val_loss: 0.9901 - val_acc: 0.7527\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.88232\n",
            "Epoch 16/300\n",
            "50000/50000 [==============================] - 91s 2ms/step - loss: 0.1223 - acc: 0.9565 - val_loss: 0.9214 - val_acc: 0.7815\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.88232\n",
            "Epoch 17/300\n",
            "50000/50000 [==============================] - 91s 2ms/step - loss: 0.1099 - acc: 0.9621 - val_loss: 0.9692 - val_acc: 0.7696\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.88232\n",
            "Epoch 18/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0956 - acc: 0.9669 - val_loss: 1.1576 - val_acc: 0.7480\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.88232\n",
            "Epoch 19/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0920 - acc: 0.9679 - val_loss: 1.0313 - val_acc: 0.7692\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.88232\n",
            "Epoch 20/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0933 - acc: 0.9668 - val_loss: 0.9175 - val_acc: 0.7866\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.88232\n",
            "Epoch 21/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0747 - acc: 0.9740 - val_loss: 1.1793 - val_acc: 0.7599\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.88232\n",
            "Epoch 22/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0802 - acc: 0.9716 - val_loss: 1.0794 - val_acc: 0.7725\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.88232\n",
            "Epoch 23/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0681 - acc: 0.9765 - val_loss: 1.0282 - val_acc: 0.7801\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.88232\n",
            "Epoch 24/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0652 - acc: 0.9777 - val_loss: 1.4540 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.88232\n",
            "Epoch 25/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0660 - acc: 0.9771 - val_loss: 1.3835 - val_acc: 0.7463\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.88232\n",
            "Epoch 26/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0645 - acc: 0.9770 - val_loss: 1.1239 - val_acc: 0.7737\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.88232\n",
            "Epoch 27/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0575 - acc: 0.9802 - val_loss: 1.2826 - val_acc: 0.7588\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.88232\n",
            "Epoch 28/300\n",
            "50000/50000 [==============================] - 91s 2ms/step - loss: 0.0517 - acc: 0.9818 - val_loss: 1.3263 - val_acc: 0.7394\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.88232\n",
            "Epoch 29/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0569 - acc: 0.9807 - val_loss: 1.2651 - val_acc: 0.7604\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.88232\n",
            "Epoch 30/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0520 - acc: 0.9822 - val_loss: 1.2107 - val_acc: 0.7628\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.88232\n",
            "Epoch 31/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0839 - acc: 0.9731 - val_loss: 1.1237 - val_acc: 0.7604\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.88232\n",
            "Epoch 32/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0543 - acc: 0.9815 - val_loss: 1.2163 - val_acc: 0.7739\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.88232\n",
            "Epoch 33/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0427 - acc: 0.9853 - val_loss: 1.3818 - val_acc: 0.7448\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.88232\n",
            "Epoch 34/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0403 - acc: 0.9869 - val_loss: 1.1445 - val_acc: 0.7802\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.88232\n",
            "Epoch 35/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0431 - acc: 0.9851 - val_loss: 1.2447 - val_acc: 0.7586\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.88232\n",
            "Epoch 36/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0404 - acc: 0.9864 - val_loss: 1.5310 - val_acc: 0.7138\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.88232\n",
            "Epoch 37/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0431 - acc: 0.9856 - val_loss: 1.3577 - val_acc: 0.7484\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.88232\n",
            "Epoch 38/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0426 - acc: 0.9848 - val_loss: 1.1376 - val_acc: 0.7825\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.88232\n",
            "Epoch 39/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0428 - acc: 0.9858 - val_loss: 1.2355 - val_acc: 0.7640\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.88232\n",
            "Epoch 40/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0355 - acc: 0.9879 - val_loss: 1.2400 - val_acc: 0.7759\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.88232\n",
            "Epoch 41/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0350 - acc: 0.9883 - val_loss: 1.1154 - val_acc: 0.7898\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.88232\n",
            "Epoch 42/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0332 - acc: 0.9885 - val_loss: 1.1533 - val_acc: 0.7897\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.88232\n",
            "Epoch 43/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0364 - acc: 0.9873 - val_loss: 1.1064 - val_acc: 0.7856\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.88232\n",
            "Epoch 44/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0325 - acc: 0.9889 - val_loss: 1.1395 - val_acc: 0.7810\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.88232\n",
            "Epoch 45/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0313 - acc: 0.9897 - val_loss: 1.1990 - val_acc: 0.7928\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.88232\n",
            "Epoch 46/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0295 - acc: 0.9901 - val_loss: 1.8996 - val_acc: 0.7026\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.88232\n",
            "Epoch 47/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0337 - acc: 0.9887 - val_loss: 1.2041 - val_acc: 0.7746\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.88232\n",
            "Epoch 48/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0308 - acc: 0.9894 - val_loss: 1.1516 - val_acc: 0.7888\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.88232\n",
            "Epoch 49/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0343 - acc: 0.9880 - val_loss: 1.2047 - val_acc: 0.7859\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.88232\n",
            "Epoch 50/300\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0299 - acc: 0.9903 - val_loss: 1.2177 - val_acc: 0.7790\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.88232\n",
            "Epoch 51/300\n",
            "29440/50000 [================>.............] - ETA: 36s - loss: 0.0278 - acc: 0.9915"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-a3c52e7e7fc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     callbacks=[checkpoint])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTfZIGrf4Uyd",
        "colab_type": "code",
        "outputId": "e4ecdd24-651f-4625-b844-4002a76260b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"Yolo_Basic_model2.h5\")\n",
        "print(\"Saved the model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 9s 943us/step\n",
            "Test loss: 1.168554341685772\n",
            "Test accuracy: 0.7915\n",
            "Saved the model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jiyb9TlVGsZs",
        "colab_type": "code",
        "outputId": "e298634b-c3aa-4d14-9a47-da99acedf2f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "model.save_weights(\"Yolo_Basic_model2.h5\")\n",
        "print(\"Saved the model to disk\")\n",
        "from google.colab import files\n",
        "\n",
        "files.download('Yolo_Basic_model2.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved the model to disk\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "Exception happened during processing of request from ('::ffff:127.0.0.1', 37702, 0, 0)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
            "    self.process_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
            "    self.finish_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
            "    self.RequestHandlerClass(request, client_address, self)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
            "    self.handle()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 418, in handle\n",
            "    self.handle_one_request()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 406, in handle_one_request\n",
            "    method()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 639, in do_GET\n",
            "    self.copyfile(f, self.wfile)\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 800, in copyfile\n",
            "    shutil.copyfileobj(source, outputfile)\n",
            "  File \"/usr/lib/python3.6/shutil.py\", line 82, in copyfileobj\n",
            "    fdst.write(buf)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 800, in write\n",
            "    self._sock.sendall(b)\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n",
            "----------------------------------------\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9A3pesKbUJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}